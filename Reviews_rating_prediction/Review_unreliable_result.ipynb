{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 16:59:02.339739: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-05-27 16:59:02.339770: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-05-27 16:59:02.339790: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-05-27 16:59:02.344622: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-05-27 16:59:02.967337: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/hao/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/hao/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package vader_lexicon to\n",
      "[nltk_data]     /home/hao/nltk_data...\n",
      "[nltk_data]   Package vader_lexicon is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/hao/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to /home/hao/nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')  \n",
    "nltk.download('stopwords')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function define\n",
    "def contributions_range(value):\n",
    "    if value <= 5:\n",
    "        return 1\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "def hotel_star_range(value):\n",
    "    if value <= 2.0:\n",
    "        return 1\n",
    "    elif value >= 2.5 and value <= 3.0:\n",
    "        return 1\n",
    "    elif value >= 3.5 and value <= 4.0:\n",
    "        return 2\n",
    "    else:\n",
    "        return 2\n",
    "    \n",
    "# text preprocessing\n",
    "def decontracting(text):\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"don\\'t\", \"do not\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'bout\", \"about\", text)\n",
    "    text = re.sub(r\"\\'til\", \"until\", text)\n",
    "    return text\n",
    "\n",
    "stopwords_list = stopwords.words('english')\n",
    "def remove_stopwords(tokens):\n",
    "    texts = [i for i in tokens if i not in stopwords_list]\n",
    "    return texts\n",
    "\n",
    "\n",
    "def lemmatization(tokens):\n",
    "  lemmatizer = WordNetLemmatizer()\n",
    "  lemmatized_tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "  return lemmatized_tokens\n",
    "\n",
    "\n",
    "def word_preprocess(df, column_name):\n",
    "  #lowercase\n",
    "  df[column_name] = df[column_name].apply(lambda x: str(x).lower())\n",
    "\n",
    "  #decontracting\n",
    "  df[column_name] = df[column_name].apply(decontracting)\n",
    "\n",
    "  #remove tags, punctuations, numbers\n",
    "  df[column_name] = df[column_name].apply(lambda x: re.sub('[^a-zA-Z!]', ' ', x))\n",
    "\n",
    "  #tokenization\n",
    "  import nltk\n",
    "  nltk.download('punkt')\n",
    "  df[column_name] = df[column_name].apply(lambda x: nltk.word_tokenize(x))\n",
    "\n",
    "  #remove stopwords\n",
    "  df[column_name] = df[column_name].apply(remove_stopwords)\n",
    "  return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_locID</th>\n",
       "      <th>Hotel_geoID_x</th>\n",
       "      <th>Review_id</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Date_of_stay</th>\n",
       "      <th>Reviewer_Contributions</th>\n",
       "      <th>Reviewer_helpful_vote</th>\n",
       "      <th>Review_Rating</th>\n",
       "      <th>Trip_type</th>\n",
       "      <th>Review_helpful_votes</th>\n",
       "      <th>...</th>\n",
       "      <th>Resaurant_count</th>\n",
       "      <th>Attractions_count</th>\n",
       "      <th>Hotel_styles</th>\n",
       "      <th>Popular_mentions</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>Compound_Score</th>\n",
       "      <th>Unreliable</th>\n",
       "      <th>Stanza_Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23448880</td>\n",
       "      <td>60763</td>\n",
       "      <td>916928494</td>\n",
       "      <td>Sep 16</td>\n",
       "      <td>September 2023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Traveled on business</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>348.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>['Business']</td>\n",
       "      <td>['front desk', 'landmark view', 'city view roo...</td>\n",
       "      <td>66</td>\n",
       "      <td>Unfriendly staff and dirty</td>\n",
       "      <td>I travel a lot - and I am in general very flex...</td>\n",
       "      <td>-0.4095</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23448880</td>\n",
       "      <td>60763</td>\n",
       "      <td>828890910</td>\n",
       "      <td>Feb 2022</td>\n",
       "      <td>February 2022</td>\n",
       "      <td>45</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>348.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>['Business']</td>\n",
       "      <td>['front desk', 'landmark view', 'city view roo...</td>\n",
       "      <td>115</td>\n",
       "      <td>Perfect for Us</td>\n",
       "      <td>We recently chose Motto for an overnight in NY...</td>\n",
       "      <td>0.9903</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23448880</td>\n",
       "      <td>60763</td>\n",
       "      <td>915189618</td>\n",
       "      <td>Sep 6</td>\n",
       "      <td>September 2023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Traveled on business</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>348.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>['Business']</td>\n",
       "      <td>['front desk', 'landmark view', 'city view roo...</td>\n",
       "      <td>99</td>\n",
       "      <td>Not satisfied with the overall experience</td>\n",
       "      <td>The rooms are two small for the price that you...</td>\n",
       "      <td>-0.0121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23448880</td>\n",
       "      <td>60763</td>\n",
       "      <td>915010751</td>\n",
       "      <td>Sep 5</td>\n",
       "      <td>September 2023</td>\n",
       "      <td>68</td>\n",
       "      <td>88</td>\n",
       "      <td>5</td>\n",
       "      <td>Traveled with family</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>348.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>['Business']</td>\n",
       "      <td>['front desk', 'landmark view', 'city view roo...</td>\n",
       "      <td>152</td>\n",
       "      <td>Magnificent Motto - fantastic staff</td>\n",
       "      <td>I have just returned home after a five day sta...</td>\n",
       "      <td>0.9746</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23448880</td>\n",
       "      <td>60763</td>\n",
       "      <td>914794870</td>\n",
       "      <td>Sep 4</td>\n",
       "      <td>August 2023</td>\n",
       "      <td>179</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>Traveled solo</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>348.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>['Business']</td>\n",
       "      <td>['front desk', 'landmark view', 'city view roo...</td>\n",
       "      <td>201</td>\n",
       "      <td>Worthy of a 5-star rating!</td>\n",
       "      <td>I did not believe the overwhelming 5-star revi...</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65977</th>\n",
       "      <td>12841013</td>\n",
       "      <td>35805</td>\n",
       "      <td>536016764</td>\n",
       "      <td>Oct 2017</td>\n",
       "      <td>October 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>Traveled solo</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>209.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>107</td>\n",
       "      <td>Great cost benefit</td>\n",
       "      <td>I stayed in the loop suites from 10/19/17 to 1...</td>\n",
       "      <td>0.9891</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65978</th>\n",
       "      <td>12841013</td>\n",
       "      <td>35805</td>\n",
       "      <td>535664344</td>\n",
       "      <td>Oct 2017</td>\n",
       "      <td>October 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Traveled solo</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>209.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>43</td>\n",
       "      <td>AWESOME</td>\n",
       "      <td>I enjoy my stay! Very nice and very clean and ...</td>\n",
       "      <td>0.9703</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65979</th>\n",
       "      <td>12841013</td>\n",
       "      <td>35805</td>\n",
       "      <td>535094403</td>\n",
       "      <td>Oct 2017</td>\n",
       "      <td>January 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Traveled solo</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>209.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>46</td>\n",
       "      <td>Very good hotel, highly recommended</td>\n",
       "      <td>I've stayed in this apartment hotel in January...</td>\n",
       "      <td>0.7639</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65980</th>\n",
       "      <td>12841013</td>\n",
       "      <td>35805</td>\n",
       "      <td>531949578</td>\n",
       "      <td>Oct 2017</td>\n",
       "      <td>May 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Traveled as a couple</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>209.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>158</td>\n",
       "      <td>Shocking</td>\n",
       "      <td>We booked an apartment for 4 people, 2 couples...</td>\n",
       "      <td>-0.5707</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65981</th>\n",
       "      <td>12841013</td>\n",
       "      <td>35805</td>\n",
       "      <td>531808345</td>\n",
       "      <td>Oct 2017</td>\n",
       "      <td>October 2017</td>\n",
       "      <td>40</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>Traveled with friends</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>209.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>62</td>\n",
       "      <td>Horrible!!!</td>\n",
       "      <td>I'm sorry for my English, but I write why ever...</td>\n",
       "      <td>0.2937</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>65982 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Hotel_locID  Hotel_geoID_x  Review_id Review_Date    Date_of_stay  \\\n",
       "0         23448880          60763  916928494      Sep 16  September 2023   \n",
       "1         23448880          60763  828890910    Feb 2022   February 2022   \n",
       "2         23448880          60763  915189618       Sep 6  September 2023   \n",
       "3         23448880          60763  915010751       Sep 5  September 2023   \n",
       "4         23448880          60763  914794870       Sep 4     August 2023   \n",
       "...            ...            ...        ...         ...             ...   \n",
       "65977     12841013          35805  536016764    Oct 2017    October 2017   \n",
       "65978     12841013          35805  535664344    Oct 2017    October 2017   \n",
       "65979     12841013          35805  535094403    Oct 2017    January 2017   \n",
       "65980     12841013          35805  531949578    Oct 2017        May 2017   \n",
       "65981     12841013          35805  531808345    Oct 2017    October 2017   \n",
       "\n",
       "       Reviewer_Contributions  Reviewer_helpful_vote  Review_Rating  \\\n",
       "0                           0                      0              1   \n",
       "1                          45                     26              5   \n",
       "2                           0                      0              3   \n",
       "3                          68                     88              5   \n",
       "4                         179                     68              5   \n",
       "...                       ...                    ...            ...   \n",
       "65977                       0                      0              4   \n",
       "65978                       0                      0              5   \n",
       "65979                       0                      0              5   \n",
       "65980                       0                      0              1   \n",
       "65981                      40                     31              1   \n",
       "\n",
       "                   Trip_type  Review_helpful_votes  ...  Resaurant_count  \\\n",
       "0       Traveled on business                     1  ...            348.0   \n",
       "1                        NaN                     8  ...            348.0   \n",
       "2       Traveled on business                     0  ...            348.0   \n",
       "3       Traveled with family                     1  ...            348.0   \n",
       "4              Traveled solo                     0  ...            348.0   \n",
       "...                      ...                   ...  ...              ...   \n",
       "65977          Traveled solo                     0  ...            209.0   \n",
       "65978          Traveled solo                     0  ...            209.0   \n",
       "65979          Traveled solo                     0  ...            209.0   \n",
       "65980   Traveled as a couple                     0  ...            209.0   \n",
       "65981  Traveled with friends                     0  ...            209.0   \n",
       "\n",
       "       Attractions_count  Hotel_styles  \\\n",
       "0                  100.0  ['Business']   \n",
       "1                  100.0  ['Business']   \n",
       "2                  100.0  ['Business']   \n",
       "3                  100.0  ['Business']   \n",
       "4                  100.0  ['Business']   \n",
       "...                  ...           ...   \n",
       "65977               90.0            []   \n",
       "65978               90.0            []   \n",
       "65979               90.0            []   \n",
       "65980               90.0            []   \n",
       "65981               90.0            []   \n",
       "\n",
       "                                        Popular_mentions  WordCount  \\\n",
       "0      ['front desk', 'landmark view', 'city view roo...         66   \n",
       "1      ['front desk', 'landmark view', 'city view roo...        115   \n",
       "2      ['front desk', 'landmark view', 'city view roo...         99   \n",
       "3      ['front desk', 'landmark view', 'city view roo...        152   \n",
       "4      ['front desk', 'landmark view', 'city view roo...        201   \n",
       "...                                                  ...        ...   \n",
       "65977                                                 []        107   \n",
       "65978                                                 []         43   \n",
       "65979                                                 []         46   \n",
       "65980                                                 []        158   \n",
       "65981                                                 []         62   \n",
       "\n",
       "                                           Title  \\\n",
       "0                     Unfriendly staff and dirty   \n",
       "1                                 Perfect for Us   \n",
       "2      Not satisfied with the overall experience   \n",
       "3            Magnificent Motto - fantastic staff   \n",
       "4                     Worthy of a 5-star rating!   \n",
       "...                                          ...   \n",
       "65977                         Great cost benefit   \n",
       "65978                                    AWESOME   \n",
       "65979        Very good hotel, highly recommended   \n",
       "65980                                   Shocking   \n",
       "65981                                Horrible!!!   \n",
       "\n",
       "                                                  Review Compound_Score  \\\n",
       "0      I travel a lot - and I am in general very flex...        -0.4095   \n",
       "1      We recently chose Motto for an overnight in NY...         0.9903   \n",
       "2      The rooms are two small for the price that you...        -0.0121   \n",
       "3      I have just returned home after a five day sta...         0.9746   \n",
       "4      I did not believe the overwhelming 5-star revi...         0.9949   \n",
       "...                                                  ...            ...   \n",
       "65977  I stayed in the loop suites from 10/19/17 to 1...         0.9891   \n",
       "65978  I enjoy my stay! Very nice and very clean and ...         0.9703   \n",
       "65979  I've stayed in this apartment hotel in January...         0.7639   \n",
       "65980  We booked an apartment for 4 people, 2 couples...        -0.5707   \n",
       "65981  I'm sorry for my English, but I write why ever...         0.2937   \n",
       "\n",
       "       Unreliable Stanza_Score  \n",
       "0               0            0  \n",
       "1               0            2  \n",
       "2               0            0  \n",
       "3               0            2  \n",
       "4               0            2  \n",
       "...           ...          ...  \n",
       "65977           0            2  \n",
       "65978           0            2  \n",
       "65979           0            2  \n",
       "65980           0            0  \n",
       "65981           0            0  \n",
       "\n",
       "[65982 rows x 24 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../Final_Datasets/TA_combined_df_City_tourism_type_VADER_final_Stanza.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_processed = df.dropna(subset=['Hotel_star'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_462673/1132114254.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_processed['Reviewer_Contributions_range'] = df_processed['Reviewer_Contributions'].apply(contributions_range)\n",
      "/tmp/ipykernel_462673/1132114254.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_processed['Hotel_star_range'] = df_processed['Hotel_star'].apply(hotel_star_range)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hotel_locID</th>\n",
       "      <th>Hotel_geoID_x</th>\n",
       "      <th>Review_id</th>\n",
       "      <th>Review_Date</th>\n",
       "      <th>Date_of_stay</th>\n",
       "      <th>Reviewer_Contributions</th>\n",
       "      <th>Reviewer_helpful_vote</th>\n",
       "      <th>Review_Rating</th>\n",
       "      <th>Trip_type</th>\n",
       "      <th>Review_helpful_votes</th>\n",
       "      <th>...</th>\n",
       "      <th>Hotel_styles</th>\n",
       "      <th>Popular_mentions</th>\n",
       "      <th>WordCount</th>\n",
       "      <th>Title</th>\n",
       "      <th>Review</th>\n",
       "      <th>Compound_Score</th>\n",
       "      <th>Unreliable</th>\n",
       "      <th>Stanza_Score</th>\n",
       "      <th>Reviewer_Contributions_range</th>\n",
       "      <th>Hotel_star_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>23448880</td>\n",
       "      <td>60763</td>\n",
       "      <td>916928494</td>\n",
       "      <td>Sep 16</td>\n",
       "      <td>September 2023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Traveled on business</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>['Business']</td>\n",
       "      <td>['front desk', 'landmark view', 'city view roo...</td>\n",
       "      <td>66</td>\n",
       "      <td>Unfriendly staff and dirty</td>\n",
       "      <td>I travel a lot - and I am in general very flex...</td>\n",
       "      <td>-0.4095</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>23448880</td>\n",
       "      <td>60763</td>\n",
       "      <td>828890910</td>\n",
       "      <td>Feb 2022</td>\n",
       "      <td>February 2022</td>\n",
       "      <td>45</td>\n",
       "      <td>26</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8</td>\n",
       "      <td>...</td>\n",
       "      <td>['Business']</td>\n",
       "      <td>['front desk', 'landmark view', 'city view roo...</td>\n",
       "      <td>115</td>\n",
       "      <td>Perfect for Us</td>\n",
       "      <td>We recently chose Motto for an overnight in NY...</td>\n",
       "      <td>0.9903</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23448880</td>\n",
       "      <td>60763</td>\n",
       "      <td>915189618</td>\n",
       "      <td>Sep 6</td>\n",
       "      <td>September 2023</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Traveled on business</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>['Business']</td>\n",
       "      <td>['front desk', 'landmark view', 'city view roo...</td>\n",
       "      <td>99</td>\n",
       "      <td>Not satisfied with the overall experience</td>\n",
       "      <td>The rooms are two small for the price that you...</td>\n",
       "      <td>-0.0121</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23448880</td>\n",
       "      <td>60763</td>\n",
       "      <td>915010751</td>\n",
       "      <td>Sep 5</td>\n",
       "      <td>September 2023</td>\n",
       "      <td>68</td>\n",
       "      <td>88</td>\n",
       "      <td>5</td>\n",
       "      <td>Traveled with family</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>['Business']</td>\n",
       "      <td>['front desk', 'landmark view', 'city view roo...</td>\n",
       "      <td>152</td>\n",
       "      <td>Magnificent Motto - fantastic staff</td>\n",
       "      <td>I have just returned home after a five day sta...</td>\n",
       "      <td>0.9746</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>23448880</td>\n",
       "      <td>60763</td>\n",
       "      <td>914794870</td>\n",
       "      <td>Sep 4</td>\n",
       "      <td>August 2023</td>\n",
       "      <td>179</td>\n",
       "      <td>68</td>\n",
       "      <td>5</td>\n",
       "      <td>Traveled solo</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>['Business']</td>\n",
       "      <td>['front desk', 'landmark view', 'city view roo...</td>\n",
       "      <td>201</td>\n",
       "      <td>Worthy of a 5-star rating!</td>\n",
       "      <td>I did not believe the overwhelming 5-star revi...</td>\n",
       "      <td>0.9949</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65954</th>\n",
       "      <td>290675</td>\n",
       "      <td>35805</td>\n",
       "      <td>17172887</td>\n",
       "      <td>Jun 2008</td>\n",
       "      <td>June 2008</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>Traveled with family</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>78</td>\n",
       "      <td>Loved the Amber Inn</td>\n",
       "      <td>I loved staying at the Amber Inn!!! By me bein...</td>\n",
       "      <td>0.9112</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65955</th>\n",
       "      <td>290675</td>\n",
       "      <td>35805</td>\n",
       "      <td>8498082</td>\n",
       "      <td>Aug 2007</td>\n",
       "      <td>August 2007</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>48</td>\n",
       "      <td>Cannot get any better for the price</td>\n",
       "      <td>This hotel I would recommend to anyone. The st...</td>\n",
       "      <td>0.9485</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65956</th>\n",
       "      <td>290675</td>\n",
       "      <td>35805</td>\n",
       "      <td>6916950</td>\n",
       "      <td>Mar 2007</td>\n",
       "      <td>March 2007</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>Traveled with family</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>512</td>\n",
       "      <td>Disgusted</td>\n",
       "      <td>On 03-03-07, my family and I got a room from T...</td>\n",
       "      <td>-0.9605</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65957</th>\n",
       "      <td>290675</td>\n",
       "      <td>35805</td>\n",
       "      <td>6898967</td>\n",
       "      <td>Feb 2007</td>\n",
       "      <td>March 2007</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>Traveled on business</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>64</td>\n",
       "      <td>Wow! What a great place for the price!</td>\n",
       "      <td>I enjoyed my stay at the Amber Inn near souths...</td>\n",
       "      <td>0.9601</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65958</th>\n",
       "      <td>290675</td>\n",
       "      <td>35805</td>\n",
       "      <td>4372065</td>\n",
       "      <td>Jan 2006</td>\n",
       "      <td>January 2006</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>[]</td>\n",
       "      <td>[]</td>\n",
       "      <td>114</td>\n",
       "      <td>Good space for the price</td>\n",
       "      <td>I really enjoyed the hotel and plan to go back...</td>\n",
       "      <td>0.9544</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>59822 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Hotel_locID  Hotel_geoID_x  Review_id Review_Date    Date_of_stay  \\\n",
       "0         23448880          60763  916928494      Sep 16  September 2023   \n",
       "1         23448880          60763  828890910    Feb 2022   February 2022   \n",
       "2         23448880          60763  915189618       Sep 6  September 2023   \n",
       "3         23448880          60763  915010751       Sep 5  September 2023   \n",
       "4         23448880          60763  914794870       Sep 4     August 2023   \n",
       "...            ...            ...        ...         ...             ...   \n",
       "65954       290675          35805   17172887    Jun 2008       June 2008   \n",
       "65955       290675          35805    8498082    Aug 2007     August 2007   \n",
       "65956       290675          35805    6916950    Mar 2007      March 2007   \n",
       "65957       290675          35805    6898967    Feb 2007      March 2007   \n",
       "65958       290675          35805    4372065    Jan 2006    January 2006   \n",
       "\n",
       "       Reviewer_Contributions  Reviewer_helpful_vote  Review_Rating  \\\n",
       "0                           0                      0              1   \n",
       "1                          45                     26              5   \n",
       "2                           0                      0              3   \n",
       "3                          68                     88              5   \n",
       "4                         179                     68              5   \n",
       "...                       ...                    ...            ...   \n",
       "65954                       0                      2              4   \n",
       "65955                       8                      9              5   \n",
       "65956                       0                      7              1   \n",
       "65957                       0                      0              5   \n",
       "65958                       0                     33              5   \n",
       "\n",
       "                  Trip_type  Review_helpful_votes  ...  Hotel_styles  \\\n",
       "0      Traveled on business                     1  ...  ['Business']   \n",
       "1                       NaN                     8  ...  ['Business']   \n",
       "2      Traveled on business                     0  ...  ['Business']   \n",
       "3      Traveled with family                     1  ...  ['Business']   \n",
       "4             Traveled solo                     0  ...  ['Business']   \n",
       "...                     ...                   ...  ...           ...   \n",
       "65954  Traveled with family                     0  ...            []   \n",
       "65955                   NaN                     0  ...            []   \n",
       "65956  Traveled with family                     0  ...            []   \n",
       "65957  Traveled on business                     0  ...            []   \n",
       "65958                   NaN                     0  ...            []   \n",
       "\n",
       "                                        Popular_mentions  WordCount  \\\n",
       "0      ['front desk', 'landmark view', 'city view roo...         66   \n",
       "1      ['front desk', 'landmark view', 'city view roo...        115   \n",
       "2      ['front desk', 'landmark view', 'city view roo...         99   \n",
       "3      ['front desk', 'landmark view', 'city view roo...        152   \n",
       "4      ['front desk', 'landmark view', 'city view roo...        201   \n",
       "...                                                  ...        ...   \n",
       "65954                                                 []         78   \n",
       "65955                                                 []         48   \n",
       "65956                                                 []        512   \n",
       "65957                                                 []         64   \n",
       "65958                                                 []        114   \n",
       "\n",
       "                                           Title  \\\n",
       "0                     Unfriendly staff and dirty   \n",
       "1                                 Perfect for Us   \n",
       "2      Not satisfied with the overall experience   \n",
       "3            Magnificent Motto - fantastic staff   \n",
       "4                     Worthy of a 5-star rating!   \n",
       "...                                          ...   \n",
       "65954                        Loved the Amber Inn   \n",
       "65955        Cannot get any better for the price   \n",
       "65956                                  Disgusted   \n",
       "65957     Wow! What a great place for the price!   \n",
       "65958                   Good space for the price   \n",
       "\n",
       "                                                  Review  Compound_Score  \\\n",
       "0      I travel a lot - and I am in general very flex...         -0.4095   \n",
       "1      We recently chose Motto for an overnight in NY...          0.9903   \n",
       "2      The rooms are two small for the price that you...         -0.0121   \n",
       "3      I have just returned home after a five day sta...          0.9746   \n",
       "4      I did not believe the overwhelming 5-star revi...          0.9949   \n",
       "...                                                  ...             ...   \n",
       "65954  I loved staying at the Amber Inn!!! By me bein...          0.9112   \n",
       "65955  This hotel I would recommend to anyone. The st...          0.9485   \n",
       "65956  On 03-03-07, my family and I got a room from T...         -0.9605   \n",
       "65957  I enjoyed my stay at the Amber Inn near souths...          0.9601   \n",
       "65958  I really enjoyed the hotel and plan to go back...          0.9544   \n",
       "\n",
       "      Unreliable Stanza_Score  Reviewer_Contributions_range Hotel_star_range  \n",
       "0              0            0                             1                2  \n",
       "1              0            2                             2                2  \n",
       "2              0            0                             1                2  \n",
       "3              0            2                             2                2  \n",
       "4              0            2                             2                2  \n",
       "...          ...          ...                           ...              ...  \n",
       "65954          0            2                             1                1  \n",
       "65955          0            2                             2                1  \n",
       "65956          0            0                             1                1  \n",
       "65957          0            2                             1                1  \n",
       "65958          0            2                             1                1  \n",
       "\n",
       "[59822 rows x 26 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create new columns\n",
    "df_processed['Reviewer_Contributions_range'] = df_processed['Reviewer_Contributions'].apply(contributions_range)\n",
    "df_processed['Hotel_star_range'] = df_processed['Hotel_star'].apply(hotel_star_range)\n",
    "df_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split 4 sub-datasets\n",
    "LCLS = df_processed[(df_processed['Reviewer_Contributions_range'] == 1) & (df_processed['Hotel_star_range'] == 1)]\n",
    "LCHS = df_processed[(df_processed['Reviewer_Contributions_range'] == 1) & (df_processed['Hotel_star_range'] == 2)]\n",
    "HCLS = df_processed[(df_processed['Reviewer_Contributions_range'] == 2) & (df_processed['Hotel_star_range'] == 1)]\n",
    "HCHS = df_processed[(df_processed['Reviewer_Contributions_range'] == 2) & (df_processed['Hotel_star_range'] == 2)]\n",
    "\n",
    "# split unreliable reviews\n",
    "LCLS_unreliable = LCLS[LCLS['Unreliable'] == 1]\n",
    "LCHS_unreliable = LCHS[LCHS['Unreliable'] == 1]\n",
    "HCLS_unreliable = HCLS[HCLS['Unreliable'] == 1]\n",
    "HCHS_unreliable = HCHS[HCHS['Unreliable'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save to csv\n",
    "# LCLS_unreliable.to_csv('../../Final_Datasets/Unreliable_datasets/LCLS_unreliable.csv', index=False)\n",
    "# LCHS_unreliable.to_csv('../../Final_Datasets/Unreliable_datasets/LCHS_unreliable.csv', index=False)\n",
    "# HCLS_unreliable.to_csv('../../Final_Datasets/Unreliable_datasets/HCLS_unreliable.csv', index=False)\n",
    "# HCHS_unreliable.to_csv('../../Final_Datasets/Unreliable_datasets/HCHS_unreliable.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text preprocessing\n",
    "# LCLS_unreliable_text_preprocessed_df = word_preprocess(LCLS_unreliable,'Review')\n",
    "# LCHS_unreliable_text_preprocessed_df = word_preprocess(LCHS_unreliable,'Review')\n",
    "# HCLS_unreliable_text_preprocessed_df = word_preprocess(HCLS_unreliable,'Review')\n",
    "# HCHS_unreliable_text_preprocessed_df = word_preprocess(HCHS_unreliable,'Review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "518      The room is too smaller for the high price, an...\n",
       "548      Clogged sink would not drain. I appreciated th...\n",
       "1411     Was an okay place to stay but we found a coupl...\n",
       "1503     Stayed here for 4 nights from 1 Sept. On arriv...\n",
       "2028     Overall this was an average hotel stay. We had...\n",
       "                               ...                        \n",
       "62939    The employee at the front desk was extremely p...\n",
       "63132    Flight was cancelled leaving me scrambling to ...\n",
       "65607    I was expecting a room resembling the image yo...\n",
       "65685    This hotel is well located but our room was ol...\n",
       "65863    The rooms were large, clean and the staff was ...\n",
       "Name: Review, Length: 182, dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LCLS_unreliable['Review']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split unreliable dataset into 2 columns\n",
    "selected_columns_unreliable = ['Review', 'Review_Rating']\n",
    "LCLS_text_unreliable = LCLS_unreliable.loc[:, selected_columns_unreliable]\n",
    "LCHS_text_unreliable = LCHS_unreliable.loc[:, selected_columns_unreliable]\n",
    "HCLS_text_unreliable = HCLS_unreliable.loc[:, selected_columns_unreliable]\n",
    "HCHS_text_unreliable = HCHS_unreliable.loc[:, selected_columns_unreliable]\n",
    "\n",
    "# reset index\n",
    "LCLS_text_unreliable.reset_index(drop=True, inplace=True)\n",
    "LCHS_text_unreliable.reset_index(drop=True, inplace=True)\n",
    "HCLS_text_unreliable.reset_index(drop=True, inplace=True)\n",
    "HCHS_text_unreliable.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# let reviews in each row become a string\n",
    "# LCLS_text_unreliable['Review'] = [' '.join(text) for text in LCLS_text_unreliable['Review']]\n",
    "# LCHS_text_unreliable['Review'] = [' '.join(text) for text in LCHS_text_unreliable['Review']]\n",
    "# HCLS_text_unreliable['Review'] = [' '.join(text) for text in HCLS_text_unreliable['Review']]\n",
    "# HCHS_text_unreliable['Review'] = [' '.join(text) for text in HCHS_text_unreliable['Review']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCLS_unreliable_X = LCLS_text_unreliable['Review']\n",
    "LCLS_unreliable_y = LCLS_text_unreliable['Review_Rating']\n",
    "\n",
    "LCHS_unreliable_X = LCHS_text_unreliable['Review']\n",
    "LCHS_unreliable_y = LCHS_text_unreliable['Review_Rating']\n",
    "\n",
    "HCLS_unreliable_X = HCLS_text_unreliable['Review']\n",
    "HCLS_unreliable_y = HCLS_text_unreliable['Review_Rating']\n",
    "\n",
    "HCHS_unreliable_X = HCHS_text_unreliable['Review']\n",
    "HCHS_unreliable_y = HCHS_text_unreliable['Review_Rating']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      The room is too smaller for the high price, an...\n",
       "1      Clogged sink would not drain. I appreciated th...\n",
       "2      Was an okay place to stay but we found a coupl...\n",
       "3      Stayed here for 4 nights from 1 Sept. On arriv...\n",
       "4      Overall this was an average hotel stay. We had...\n",
       "                             ...                        \n",
       "177    The employee at the front desk was extremely p...\n",
       "178    Flight was cancelled leaving me scrambling to ...\n",
       "179    I was expecting a room resembling the image yo...\n",
       "180    This hotel is well located but our room was ol...\n",
       "181    The rooms were large, clean and the staff was ...\n",
       "Name: Review, Length: 182, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LCLS_unreliable_X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Longformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hao/Code/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BERT(longformer) model\n",
    "model_name = 'allenai/longformer-base-4096'\n",
    "tokenizer = transformers.LongformerTokenizer.from_pretrained(model_name)\n",
    "model = transformers.LongformerModel.from_pretrained(model_name).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define function\n",
    "def bert_embedding(X_train):\n",
    "    embeddings = []\n",
    "    for text in X_train:\n",
    "        # 將文本轉成BERT的輸入格式，即加上[CLS]與[SEP] token，並轉成tensor\n",
    "        encoded_text = tokenizer.encode_plus(text, add_special_tokens=True, return_tensors='pt').to(device)\n",
    "\n",
    "        # 用預訓練BERT模型轉成向量\n",
    "        with torch.no_grad():\n",
    "            model_output = model(encoded_text['input_ids'], attention_mask=encoded_text['attention_mask'])\n",
    "\n",
    "        # 取出[CLS] token對應的向量作為整個文本的向量表示\n",
    "        embeddings.append(model_output.last_hidden_state[:, 0, :].squeeze().tolist())\n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "LCLS_unreliable_X_bert = pd.DataFrame(bert_embedding(LCLS_unreliable_X))\n",
    "LCHS_unreliable_X_bert = pd.DataFrame(bert_embedding(LCHS_unreliable_X))\n",
    "HCLS_unreliable_X_bert = pd.DataFrame(bert_embedding(HCLS_unreliable_X))\n",
    "HCHS_unreliable_X_bert = pd.DataFrame(bert_embedding(HCHS_unreliable_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.050908</td>\n",
       "      <td>0.122207</td>\n",
       "      <td>0.006951</td>\n",
       "      <td>-0.149705</td>\n",
       "      <td>0.163385</td>\n",
       "      <td>-0.041357</td>\n",
       "      <td>-0.021272</td>\n",
       "      <td>0.020481</td>\n",
       "      <td>0.025886</td>\n",
       "      <td>-0.144073</td>\n",
       "      <td>...</td>\n",
       "      <td>0.014479</td>\n",
       "      <td>-0.007821</td>\n",
       "      <td>-0.062212</td>\n",
       "      <td>-0.041804</td>\n",
       "      <td>-0.013096</td>\n",
       "      <td>0.087481</td>\n",
       "      <td>0.079315</td>\n",
       "      <td>-0.131910</td>\n",
       "      <td>-0.050172</td>\n",
       "      <td>-0.028143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.056304</td>\n",
       "      <td>0.065346</td>\n",
       "      <td>-0.003244</td>\n",
       "      <td>-0.103457</td>\n",
       "      <td>0.136883</td>\n",
       "      <td>-0.013560</td>\n",
       "      <td>-0.020571</td>\n",
       "      <td>0.073960</td>\n",
       "      <td>0.031345</td>\n",
       "      <td>-0.118462</td>\n",
       "      <td>...</td>\n",
       "      <td>0.086262</td>\n",
       "      <td>-0.035446</td>\n",
       "      <td>-0.161022</td>\n",
       "      <td>-0.100020</td>\n",
       "      <td>0.057332</td>\n",
       "      <td>0.129222</td>\n",
       "      <td>0.014672</td>\n",
       "      <td>-0.127074</td>\n",
       "      <td>-0.032873</td>\n",
       "      <td>-0.039966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.059939</td>\n",
       "      <td>0.077162</td>\n",
       "      <td>0.005043</td>\n",
       "      <td>-0.143026</td>\n",
       "      <td>0.109789</td>\n",
       "      <td>-0.001913</td>\n",
       "      <td>-0.045074</td>\n",
       "      <td>-0.008334</td>\n",
       "      <td>0.051527</td>\n",
       "      <td>-0.163747</td>\n",
       "      <td>...</td>\n",
       "      <td>0.044862</td>\n",
       "      <td>-0.050243</td>\n",
       "      <td>-0.136801</td>\n",
       "      <td>-0.030328</td>\n",
       "      <td>-0.012736</td>\n",
       "      <td>0.077838</td>\n",
       "      <td>0.090204</td>\n",
       "      <td>-0.165169</td>\n",
       "      <td>0.004914</td>\n",
       "      <td>-0.010073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.044114</td>\n",
       "      <td>0.083771</td>\n",
       "      <td>0.060063</td>\n",
       "      <td>-0.152079</td>\n",
       "      <td>0.033083</td>\n",
       "      <td>-0.036279</td>\n",
       "      <td>-0.024605</td>\n",
       "      <td>0.004348</td>\n",
       "      <td>0.105753</td>\n",
       "      <td>-0.191153</td>\n",
       "      <td>...</td>\n",
       "      <td>0.023283</td>\n",
       "      <td>-0.076884</td>\n",
       "      <td>-0.104329</td>\n",
       "      <td>0.005776</td>\n",
       "      <td>0.050605</td>\n",
       "      <td>0.058708</td>\n",
       "      <td>0.029266</td>\n",
       "      <td>-0.070925</td>\n",
       "      <td>0.014324</td>\n",
       "      <td>-0.026834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.107308</td>\n",
       "      <td>0.103177</td>\n",
       "      <td>0.049286</td>\n",
       "      <td>-0.159762</td>\n",
       "      <td>0.069486</td>\n",
       "      <td>-0.017025</td>\n",
       "      <td>-0.025463</td>\n",
       "      <td>0.031742</td>\n",
       "      <td>0.081381</td>\n",
       "      <td>-0.152819</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002522</td>\n",
       "      <td>-0.029864</td>\n",
       "      <td>-0.105313</td>\n",
       "      <td>-0.019829</td>\n",
       "      <td>0.019185</td>\n",
       "      <td>0.094003</td>\n",
       "      <td>0.010118</td>\n",
       "      <td>-0.122194</td>\n",
       "      <td>-0.008311</td>\n",
       "      <td>-0.015755</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>-0.109419</td>\n",
       "      <td>0.106436</td>\n",
       "      <td>0.056269</td>\n",
       "      <td>-0.120804</td>\n",
       "      <td>0.112206</td>\n",
       "      <td>0.020836</td>\n",
       "      <td>-0.040967</td>\n",
       "      <td>0.016013</td>\n",
       "      <td>0.089292</td>\n",
       "      <td>-0.177498</td>\n",
       "      <td>...</td>\n",
       "      <td>0.057258</td>\n",
       "      <td>-0.031642</td>\n",
       "      <td>-0.133268</td>\n",
       "      <td>-0.048638</td>\n",
       "      <td>0.009734</td>\n",
       "      <td>0.082164</td>\n",
       "      <td>0.002466</td>\n",
       "      <td>-0.141618</td>\n",
       "      <td>-0.045946</td>\n",
       "      <td>0.026640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>-0.086621</td>\n",
       "      <td>0.051575</td>\n",
       "      <td>0.021621</td>\n",
       "      <td>-0.111164</td>\n",
       "      <td>0.131050</td>\n",
       "      <td>0.005625</td>\n",
       "      <td>-0.017727</td>\n",
       "      <td>0.037761</td>\n",
       "      <td>0.080737</td>\n",
       "      <td>-0.159835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013383</td>\n",
       "      <td>-0.010462</td>\n",
       "      <td>-0.101075</td>\n",
       "      <td>-0.048530</td>\n",
       "      <td>-0.012145</td>\n",
       "      <td>0.119106</td>\n",
       "      <td>-0.023878</td>\n",
       "      <td>-0.144482</td>\n",
       "      <td>-0.068421</td>\n",
       "      <td>-0.021840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>-0.044492</td>\n",
       "      <td>0.065558</td>\n",
       "      <td>-0.007216</td>\n",
       "      <td>-0.124660</td>\n",
       "      <td>0.140513</td>\n",
       "      <td>-0.048782</td>\n",
       "      <td>-0.033654</td>\n",
       "      <td>0.032306</td>\n",
       "      <td>0.046382</td>\n",
       "      <td>-0.144419</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000786</td>\n",
       "      <td>-0.024157</td>\n",
       "      <td>-0.090325</td>\n",
       "      <td>-0.051407</td>\n",
       "      <td>-0.050224</td>\n",
       "      <td>0.090551</td>\n",
       "      <td>0.034886</td>\n",
       "      <td>-0.127112</td>\n",
       "      <td>-0.019305</td>\n",
       "      <td>-0.048137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>-0.079327</td>\n",
       "      <td>0.118288</td>\n",
       "      <td>0.031631</td>\n",
       "      <td>-0.180782</td>\n",
       "      <td>0.114745</td>\n",
       "      <td>-0.039249</td>\n",
       "      <td>-0.037943</td>\n",
       "      <td>0.012342</td>\n",
       "      <td>0.053028</td>\n",
       "      <td>-0.152206</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049621</td>\n",
       "      <td>-0.046756</td>\n",
       "      <td>-0.082948</td>\n",
       "      <td>-0.019594</td>\n",
       "      <td>-0.007275</td>\n",
       "      <td>0.074594</td>\n",
       "      <td>0.035064</td>\n",
       "      <td>-0.129477</td>\n",
       "      <td>-0.003062</td>\n",
       "      <td>-0.007179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>-0.096439</td>\n",
       "      <td>0.087350</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>-0.171029</td>\n",
       "      <td>0.069621</td>\n",
       "      <td>0.010432</td>\n",
       "      <td>-0.037844</td>\n",
       "      <td>0.026500</td>\n",
       "      <td>0.085792</td>\n",
       "      <td>-0.155962</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000931</td>\n",
       "      <td>-0.007390</td>\n",
       "      <td>-0.140994</td>\n",
       "      <td>-0.032106</td>\n",
       "      <td>-0.009772</td>\n",
       "      <td>0.099002</td>\n",
       "      <td>0.014976</td>\n",
       "      <td>-0.150880</td>\n",
       "      <td>-0.011798</td>\n",
       "      <td>-0.034366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>182 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0   -0.050908  0.122207  0.006951 -0.149705  0.163385 -0.041357 -0.021272   \n",
       "1   -0.056304  0.065346 -0.003244 -0.103457  0.136883 -0.013560 -0.020571   \n",
       "2   -0.059939  0.077162  0.005043 -0.143026  0.109789 -0.001913 -0.045074   \n",
       "3   -0.044114  0.083771  0.060063 -0.152079  0.033083 -0.036279 -0.024605   \n",
       "4   -0.107308  0.103177  0.049286 -0.159762  0.069486 -0.017025 -0.025463   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "177 -0.109419  0.106436  0.056269 -0.120804  0.112206  0.020836 -0.040967   \n",
       "178 -0.086621  0.051575  0.021621 -0.111164  0.131050  0.005625 -0.017727   \n",
       "179 -0.044492  0.065558 -0.007216 -0.124660  0.140513 -0.048782 -0.033654   \n",
       "180 -0.079327  0.118288  0.031631 -0.180782  0.114745 -0.039249 -0.037943   \n",
       "181 -0.096439  0.087350  0.037300 -0.171029  0.069621  0.010432 -0.037844   \n",
       "\n",
       "          7         8         9    ...       758       759       760  \\\n",
       "0    0.020481  0.025886 -0.144073  ...  0.014479 -0.007821 -0.062212   \n",
       "1    0.073960  0.031345 -0.118462  ...  0.086262 -0.035446 -0.161022   \n",
       "2   -0.008334  0.051527 -0.163747  ...  0.044862 -0.050243 -0.136801   \n",
       "3    0.004348  0.105753 -0.191153  ...  0.023283 -0.076884 -0.104329   \n",
       "4    0.031742  0.081381 -0.152819  ...  0.002522 -0.029864 -0.105313   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "177  0.016013  0.089292 -0.177498  ...  0.057258 -0.031642 -0.133268   \n",
       "178  0.037761  0.080737 -0.159835  ...  0.013383 -0.010462 -0.101075   \n",
       "179  0.032306  0.046382 -0.144419  ... -0.000786 -0.024157 -0.090325   \n",
       "180  0.012342  0.053028 -0.152206  ...  0.049621 -0.046756 -0.082948   \n",
       "181  0.026500  0.085792 -0.155962  ...  0.000931 -0.007390 -0.140994   \n",
       "\n",
       "          761       762       763       764       765       766       767  \n",
       "0   -0.041804 -0.013096  0.087481  0.079315 -0.131910 -0.050172 -0.028143  \n",
       "1   -0.100020  0.057332  0.129222  0.014672 -0.127074 -0.032873 -0.039966  \n",
       "2   -0.030328 -0.012736  0.077838  0.090204 -0.165169  0.004914 -0.010073  \n",
       "3    0.005776  0.050605  0.058708  0.029266 -0.070925  0.014324 -0.026834  \n",
       "4   -0.019829  0.019185  0.094003  0.010118 -0.122194 -0.008311 -0.015755  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "177 -0.048638  0.009734  0.082164  0.002466 -0.141618 -0.045946  0.026640  \n",
       "178 -0.048530 -0.012145  0.119106 -0.023878 -0.144482 -0.068421 -0.021840  \n",
       "179 -0.051407 -0.050224  0.090551  0.034886 -0.127112 -0.019305 -0.048137  \n",
       "180 -0.019594 -0.007275  0.074594  0.035064 -0.129477 -0.003062 -0.007179  \n",
       "181 -0.032106 -0.009772  0.099002  0.014976 -0.150880 -0.011798 -0.034366  \n",
       "\n",
       "[182 rows x 768 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LCLS_unreliable_X_bert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-05-27 16:59:34.484334: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 16:59:34.501992: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 16:59:34.502216: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 16:59:34.503844: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 16:59:34.504015: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 16:59:34.504105: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 16:59:34.509116: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 16:59:34.509287: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 16:59:34.509387: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:894] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-05-27 16:59:34.509453: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 162 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3090, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-05-27 16:59:34.520244: I tensorflow/compiler/xla/stream_executor/cuda/cuda_driver.cc:746] failed to allocate 162.19MiB (170065920 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m6/6\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n",
      "[[[1.6141143 ]]\n",
      "\n",
      " [[0.6785921 ]]\n",
      "\n",
      " [[3.2872508 ]]\n",
      "\n",
      " [[2.4850705 ]]\n",
      "\n",
      " [[3.2471387 ]]\n",
      "\n",
      " [[1.9488622 ]]\n",
      "\n",
      " [[1.7927523 ]]\n",
      "\n",
      " [[3.803065  ]]\n",
      "\n",
      " [[3.5644584 ]]\n",
      "\n",
      " [[4.7487864 ]]\n",
      "\n",
      " [[1.3126128 ]]\n",
      "\n",
      " [[1.5054604 ]]\n",
      "\n",
      " [[1.7215164 ]]\n",
      "\n",
      " [[4.6616287 ]]\n",
      "\n",
      " [[4.4065595 ]]\n",
      "\n",
      " [[2.8291013 ]]\n",
      "\n",
      " [[3.8771217 ]]\n",
      "\n",
      " [[1.0389017 ]]\n",
      "\n",
      " [[5.097446  ]]\n",
      "\n",
      " [[1.4915597 ]]\n",
      "\n",
      " [[3.695934  ]]\n",
      "\n",
      " [[2.0425231 ]]\n",
      "\n",
      " [[0.89543724]]\n",
      "\n",
      " [[2.5256207 ]]\n",
      "\n",
      " [[4.240047  ]]\n",
      "\n",
      " [[2.7910206 ]]\n",
      "\n",
      " [[1.6878786 ]]\n",
      "\n",
      " [[0.5661218 ]]\n",
      "\n",
      " [[0.4646063 ]]\n",
      "\n",
      " [[4.350291  ]]\n",
      "\n",
      " [[2.8699994 ]]\n",
      "\n",
      " [[3.4918256 ]]\n",
      "\n",
      " [[3.8369381 ]]\n",
      "\n",
      " [[4.652214  ]]\n",
      "\n",
      " [[2.2640462 ]]\n",
      "\n",
      " [[3.9201448 ]]\n",
      "\n",
      " [[4.1602798 ]]\n",
      "\n",
      " [[4.0899577 ]]\n",
      "\n",
      " [[2.086515  ]]\n",
      "\n",
      " [[3.3712265 ]]\n",
      "\n",
      " [[1.5742192 ]]\n",
      "\n",
      " [[1.4520483 ]]\n",
      "\n",
      " [[2.5481663 ]]\n",
      "\n",
      " [[3.9126039 ]]\n",
      "\n",
      " [[1.6595402 ]]\n",
      "\n",
      " [[0.92838454]]\n",
      "\n",
      " [[1.9017489 ]]\n",
      "\n",
      " [[0.93843794]]\n",
      "\n",
      " [[4.5024934 ]]\n",
      "\n",
      " [[1.2769547 ]]\n",
      "\n",
      " [[2.1618092 ]]\n",
      "\n",
      " [[1.2211084 ]]\n",
      "\n",
      " [[2.0998194 ]]\n",
      "\n",
      " [[4.539648  ]]\n",
      "\n",
      " [[2.4164038 ]]\n",
      "\n",
      " [[1.9469227 ]]\n",
      "\n",
      " [[2.7424862 ]]\n",
      "\n",
      " [[4.3564944 ]]\n",
      "\n",
      " [[2.990763  ]]\n",
      "\n",
      " [[2.7497025 ]]\n",
      "\n",
      " [[2.1173007 ]]\n",
      "\n",
      " [[4.6546426 ]]\n",
      "\n",
      " [[5.146266  ]]\n",
      "\n",
      " [[3.8893216 ]]\n",
      "\n",
      " [[1.4564121 ]]\n",
      "\n",
      " [[4.704952  ]]\n",
      "\n",
      " [[1.1743281 ]]\n",
      "\n",
      " [[2.3061764 ]]\n",
      "\n",
      " [[4.635492  ]]\n",
      "\n",
      " [[2.0785048 ]]\n",
      "\n",
      " [[2.6735208 ]]\n",
      "\n",
      " [[1.4455919 ]]\n",
      "\n",
      " [[1.4695277 ]]\n",
      "\n",
      " [[2.824949  ]]\n",
      "\n",
      " [[1.9527841 ]]\n",
      "\n",
      " [[4.007927  ]]\n",
      "\n",
      " [[1.5904763 ]]\n",
      "\n",
      " [[1.1806922 ]]\n",
      "\n",
      " [[0.9123694 ]]\n",
      "\n",
      " [[2.1474435 ]]\n",
      "\n",
      " [[3.527505  ]]\n",
      "\n",
      " [[3.1581028 ]]\n",
      "\n",
      " [[4.050223  ]]\n",
      "\n",
      " [[4.880713  ]]\n",
      "\n",
      " [[2.006133  ]]\n",
      "\n",
      " [[3.5944374 ]]\n",
      "\n",
      " [[3.8150156 ]]\n",
      "\n",
      " [[2.9753833 ]]\n",
      "\n",
      " [[2.6726701 ]]\n",
      "\n",
      " [[3.855911  ]]\n",
      "\n",
      " [[2.4663126 ]]\n",
      "\n",
      " [[1.5731416 ]]\n",
      "\n",
      " [[1.0525053 ]]\n",
      "\n",
      " [[3.417031  ]]\n",
      "\n",
      " [[1.3952    ]]\n",
      "\n",
      " [[2.7311873 ]]\n",
      "\n",
      " [[1.0848044 ]]\n",
      "\n",
      " [[1.200364  ]]\n",
      "\n",
      " [[1.2774056 ]]\n",
      "\n",
      " [[1.6541803 ]]\n",
      "\n",
      " [[1.7158864 ]]\n",
      "\n",
      " [[1.3988266 ]]\n",
      "\n",
      " [[3.672404  ]]\n",
      "\n",
      " [[1.0491173 ]]\n",
      "\n",
      " [[2.117699  ]]\n",
      "\n",
      " [[2.6047583 ]]\n",
      "\n",
      " [[1.620714  ]]\n",
      "\n",
      " [[2.2189777 ]]\n",
      "\n",
      " [[2.1117246 ]]\n",
      "\n",
      " [[4.162469  ]]\n",
      "\n",
      " [[2.401048  ]]\n",
      "\n",
      " [[0.9812909 ]]\n",
      "\n",
      " [[5.0271745 ]]\n",
      "\n",
      " [[0.8538894 ]]\n",
      "\n",
      " [[2.4380426 ]]\n",
      "\n",
      " [[3.8597922 ]]\n",
      "\n",
      " [[2.537645  ]]\n",
      "\n",
      " [[3.5628288 ]]\n",
      "\n",
      " [[4.193846  ]]\n",
      "\n",
      " [[3.5296881 ]]\n",
      "\n",
      " [[2.135354  ]]\n",
      "\n",
      " [[3.636804  ]]\n",
      "\n",
      " [[0.8779847 ]]\n",
      "\n",
      " [[1.2353051 ]]\n",
      "\n",
      " [[4.65807   ]]\n",
      "\n",
      " [[2.5304005 ]]\n",
      "\n",
      " [[0.3668278 ]]\n",
      "\n",
      " [[1.6429927 ]]\n",
      "\n",
      " [[1.7900349 ]]\n",
      "\n",
      " [[2.2475102 ]]\n",
      "\n",
      " [[1.956236  ]]\n",
      "\n",
      " [[0.75061464]]\n",
      "\n",
      " [[2.3156083 ]]\n",
      "\n",
      " [[1.1519783 ]]\n",
      "\n",
      " [[1.7413467 ]]\n",
      "\n",
      " [[0.44358176]]\n",
      "\n",
      " [[2.9493568 ]]\n",
      "\n",
      " [[0.6650214 ]]\n",
      "\n",
      " [[0.72783494]]\n",
      "\n",
      " [[2.4983666 ]]\n",
      "\n",
      " [[2.1387045 ]]\n",
      "\n",
      " [[1.3376435 ]]\n",
      "\n",
      " [[2.348155  ]]\n",
      "\n",
      " [[3.0818942 ]]\n",
      "\n",
      " [[4.556729  ]]\n",
      "\n",
      " [[1.8299036 ]]\n",
      "\n",
      " [[1.5947196 ]]\n",
      "\n",
      " [[3.7735803 ]]\n",
      "\n",
      " [[4.913467  ]]\n",
      "\n",
      " [[2.0114713 ]]\n",
      "\n",
      " [[0.8304944 ]]\n",
      "\n",
      " [[4.2931623 ]]\n",
      "\n",
      " [[3.9557202 ]]\n",
      "\n",
      " [[0.46766675]]\n",
      "\n",
      " [[1.8318995 ]]\n",
      "\n",
      " [[3.3673275 ]]\n",
      "\n",
      " [[1.8223267 ]]\n",
      "\n",
      " [[2.7202742 ]]\n",
      "\n",
      " [[2.1480134 ]]\n",
      "\n",
      " [[3.9516852 ]]\n",
      "\n",
      " [[3.0291772 ]]\n",
      "\n",
      " [[4.568845  ]]\n",
      "\n",
      " [[2.3932385 ]]\n",
      "\n",
      " [[1.9388554 ]]\n",
      "\n",
      " [[3.5285592 ]]\n",
      "\n",
      " [[0.48343477]]\n",
      "\n",
      " [[2.2098932 ]]\n",
      "\n",
      " [[2.0100214 ]]\n",
      "\n",
      " [[3.4494326 ]]\n",
      "\n",
      " [[3.5613096 ]]\n",
      "\n",
      " [[1.7986822 ]]\n",
      "\n",
      " [[2.9049947 ]]\n",
      "\n",
      " [[4.902661  ]]\n",
      "\n",
      " [[2.324433  ]]\n",
      "\n",
      " [[2.0805504 ]]\n",
      "\n",
      " [[0.94303244]]\n",
      "\n",
      " [[0.987695  ]]\n",
      "\n",
      " [[3.8775735 ]]\n",
      "\n",
      " [[0.61615014]]\n",
      "\n",
      " [[2.0063262 ]]\n",
      "\n",
      " [[3.7343097 ]]\n",
      "\n",
      " [[2.9958436 ]]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_462673/3408578930.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  LCLS_unreliable['Predicted_Rating'] = predictions_flat\n"
     ]
    }
   ],
   "source": [
    "input_data = LCLS_unreliable_X_bert\n",
    "# 步驟 1：加載模型\n",
    "model = load_model('../../Experiment_code/Model/LCLS_lstm_model_longformer.h5')\n",
    "\n",
    "# 步驟 2：加載輸入數據\n",
    "input_data = input_data.to_numpy().reshape(input_data.shape[0], 1, input_data.shape[1])\n",
    "\n",
    "# 步驟 3：使用模型進行預測\n",
    "predictions = model.predict(input_data)\n",
    "\n",
    "predictions_flat = predictions.flatten()\n",
    "LCLS_unreliable['Predicted_Rating'] = predictions_flat\n",
    "LCLS_unreliable.to_csv('../../Final_Datasets/Unreliable_datasets/LCLS_unreliable.csv', index=False)\n",
    "\n",
    "# 輸出預測結果\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_462673/2234562453.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  LCHS_unreliable['Predicted_Rating'] = predictions_flat\n"
     ]
    }
   ],
   "source": [
    "input_data = LCHS_unreliable_X_bert\n",
    "# 步驟 1：加載模型\n",
    "model = load_model('../../Experiment_code/Model/LCHS_lstm_model_longformer.h5')\n",
    "\n",
    "# 步驟 2：加載輸入數據\n",
    "input_data = input_data.to_numpy().reshape(input_data.shape[0], 1, input_data.shape[1])\n",
    "\n",
    "# 步驟 3：使用模型進行預測\n",
    "predictions = model.predict(input_data)\n",
    "\n",
    "predictions_flat = predictions.flatten()\n",
    "LCHS_unreliable['Predicted_Rating'] = predictions_flat\n",
    "LCHS_unreliable.to_csv('../../Final_Datasets/Unreliable_datasets/LCHS_unreliable.csv', index=False)\n",
    "\n",
    "# 輸出預測結果\n",
    "# print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 14 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78b6803d7ec0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 14 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x78b6803d7ec0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_462673/1712698182.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  HCLS_unreliable['Predicted_Rating'] = predictions_flat\n"
     ]
    }
   ],
   "source": [
    "input_data = HCLS_unreliable_X_bert\n",
    "# 步驟 1：加載模型\n",
    "model = load_model('../../Experiment_code/Model/HCLS_lstm_model_longformer.h5')\n",
    "\n",
    "# 步驟 2：加載輸入數據\n",
    "input_data = input_data.to_numpy().reshape(input_data.shape[0], 1, input_data.shape[1])\n",
    "\n",
    "# 步驟 3：使用模型進行預測\n",
    "predictions = model.predict(input_data)\n",
    "\n",
    "predictions_flat = predictions.flatten()\n",
    "HCLS_unreliable['Predicted_Rating'] = predictions_flat\n",
    "HCLS_unreliable.to_csv('../../Final_Datasets/Unreliable_datasets/HCLS_unreliable.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m8/8\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_462673/1384022494.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  HCHS_unreliable['Predicted_Rating'] = predictions_flat\n"
     ]
    }
   ],
   "source": [
    "input_data = HCHS_unreliable_X_bert\n",
    "# 步驟 1：加載模型\n",
    "model = load_model('../../Experiment_code/Model/HCHS_lstm_model_longformer.h5')\n",
    "\n",
    "# 步驟 2：加載輸入數據\n",
    "input_data = input_data.to_numpy().reshape(input_data.shape[0], 1, input_data.shape[1])\n",
    "\n",
    "# 步驟 3：使用模型進行預測\n",
    "predictions = model.predict(input_data)\n",
    "\n",
    "predictions_flat = predictions.flatten()\n",
    "HCHS_unreliable['Predicted_Rating'] = predictions_flat\n",
    "HCHS_unreliable.to_csv('../../Final_Datasets/Unreliable_datasets/HCHS_unreliable.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
